{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-02T22:00:04.288188Z",
     "start_time": "2024-02-02T22:00:00.763547Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vyacheslav/Documents/projects/rubert-tiny/.venv39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/s3/hmpf_gw12rg9ltnxptr0q3pw0000gn/T/ipykernel_73981/1410809860.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch import nn\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class YesNoModel(nn.Module):\n",
    "    def set_config(self, config):\n",
    "        pass\n",
    "\n",
    "    def predict_group(self, group, txt):\n",
    "        pass\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2. Create 2 nn.Linear layers capable of handling X and y input and output shapes\n",
    "        self.layer_1 = nn.Linear(in_features=312, out_features=5)  # takes in 2 features (X), produces 5 features\n",
    "        self.layer_2 = nn.Linear(in_features=5, out_features=1)  # takes in 5 features, produces 1 feature (y)\n",
    "\n",
    "    # 3. Define a forward method containing the forward pass computation\n",
    "    def forward(self, x):\n",
    "        # Return the output of layer_2, a single feature, the same shape as y\n",
    "        return self.layer_2(\n",
    "            self.layer_1(\n",
    "                x))  # computation goes through layer_1 first then the output of layer_1 goes through layer_2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T22:01:41.651164Z",
     "start_time": "2024-02-02T22:01:41.643460Z"
    }
   },
   "id": "1d65fa9fd40b3cbc",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('model_0.picle', 'rb') as f: \n",
    "    model_0 = pickle.load(f)\n",
    "with open('model_rubertyni.picle', 'rb') as f: \n",
    "    modelrubertyni = pickle.load(f)\n",
    "with open('tokenizer.picle', 'rb') as f: \n",
    "    tokenizer = pickle.load(f)\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T22:01:42.673131Z",
     "start_time": "2024-02-02T22:01:42.554116Z"
    }
   },
   "id": "1d274f806bbd8446",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings[0].cpu().numpy()\n",
    "\n",
    "def make_predict(text, main_model, wv_model, wv_tokenizer):\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['DATA'] = [text]\n",
    "    new_df['VEC'] = new_df['DATA'].apply(lambda  x : embed_bert_cls(x, wv_model, wv_tokenizer)) \n",
    "    X_train2 = torch.from_numpy(np.stack(new_df['VEC'].values)).type(torch.float)\n",
    "    test_logits = main_model(X_train2).squeeze() \n",
    "    return int(torch.round(torch.sigmoid(test_logits)).tolist())\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T22:01:43.854298Z",
     "start_time": "2024-02-02T22:01:43.839742Z"
    }
   },
   "id": "e67b440e44e87808",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_predict(\"ну да нет\", model_0, modelrubertyni, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T22:01:44.602597Z",
     "start_time": "2024-02-02T22:01:44.581714Z"
    }
   },
   "id": "5a10a2df515ebcce",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_0.set_config({})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T22:01:45.293549Z",
     "start_time": "2024-02-02T22:01:45.287169Z"
    }
   },
   "id": "27b2c1496319df0d",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "69576f68c3dbd6ca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
